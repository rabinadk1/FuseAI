{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f0e579811ca78fa31ef045613001bef",
     "grade": false,
     "grade_id": "cell-2d5af604f4dc4f44",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Fashion MNIST\n",
    "**<div style=\"text-align: right\"> [Total score: 12]</div>**\n",
    "This dataset is from Zalando's research which consist of a training set of 60,000 examples and a test set of 10,000 examples of 28x28 grayscale images, associated with a label from 10 classes of clothing Items.\n",
    "<br>Source: https://github.com/zalandoresearch/fashion-mnist\n",
    "<br><br>**The 10 classess are**\n",
    "0. T-shirt/top;\n",
    "1. Trouser;\n",
    "2. Pullover;\n",
    "3. Dress;\n",
    "4. Coat;\n",
    "5. Sandal;\n",
    "6. Shirt;\n",
    "7. Sneaker;\n",
    "8. Bag;\n",
    "9. Ankle boot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e75c690e676c63ad797b3ff17a169edc",
     "grade": false,
     "grade_id": "cell-9806466edb2a86e1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex1: Import keras and other required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "91a4abec23f2b686d3f3cefc22788e5c",
     "grade": false,
     "grade_id": "cell-7518d4202af55fc8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for each type of label \n",
    "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
    "\n",
    "import os\n",
    "PATH=\"./Fashion MNIST/\"\n",
    "\n",
    "train_file = PATH+\"fashion-mnist_train.csv\"\n",
    "train_data = pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "NUM_CLASSES = 10\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion MNIST train -  rows: 60000  columns: 785\n"
     ]
    }
   ],
   "source": [
    "print(\"Fashion MNIST train -  rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61631919b96841e5e07f8a01a40ea319",
     "grade": false,
     "grade_id": "cell-a1b673c842f41010",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Helper Functions are provided to ease your learning\n",
    "- get_classes_distribution(data)\n",
    "- plot_label_per_class(data)\n",
    "- sample_images_data(data)\n",
    "- plot_sample_images(data_sample_images,data_sample_labels)\n",
    "- plot_count_per_class(np.argmax(y_train,axis=1))\n",
    "- get_count_per_class(np.argmax(y_train,axis=1))\n",
    "\n",
    "Use the functions on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d2d66cd882997619f7457237e173c18b",
     "grade": false,
     "grade_id": "cell-0530f6c4cedd568e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex2: Data Preprocessing\n",
    "Convert labels to categorical \n",
    "<br> Reshape and Normalise the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3baf7ff0f38ae3f493f649ddb45ccb62",
     "grade": false,
     "grade_id": "cell-2728aabfc58b2623",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(raw):\n",
    "    \"\"\"\n",
    "    Converts raw.label to categorical out_y\n",
    "    Converts images in raw.values to normalised images out_x (reshape if required)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    x_shaped_array = raw.values[:, 1:].reshape(raw.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "    out_x = x_shaped_array/255.0\n",
    "    \n",
    "    out_y = to_categorical(raw.label, NUM_CLASSES)\n",
    "#     raise NotImplementedError()\n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b284cb4e42153c8dbb47b900a1ad89d",
     "grade": false,
     "grade_id": "cell-1cb2aa2b9af8882f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex3: Preprocess and Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d68d610f3f7e24660d071b96f7ad0cc3",
     "grade": false,
     "grade_id": "cell-0ea6767f11bb3821",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the data and preprocess it\n",
    "X,y = data_preprocessing(train_data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion MNIST train -  rows: 48000  columns: (28, 28, 1)\n",
      "Fashion MNIST valid -  rows: 12000  columns: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fashion MNIST train -  rows:\",X_train.shape[0],\" columns:\", X_train.shape[1:4])\n",
    "print(\"Fashion MNIST valid -  rows:\",X_val.shape[0],\" columns:\", X_val.shape[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "409b025a31e49af62656af991b46453f",
     "grade": false,
     "grade_id": "cell-bba102edefc15c1a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex4: Build and Compile Keras Model  \n",
    "**<div style=\"text-align: right\"> [Score: 2]</div>**\n",
    "Add atleast   \n",
    "- 1 Conv2D layer\n",
    "- 1 MaxPooling layer and\n",
    "- 1 Dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "505cc600ad76f01185c53813004c22e9",
     "grade": false,
     "grade_id": "cell-1845028492073f96",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,669,706\n",
      "Trainable params: 1,668,362\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "# YOUR CODE HERE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9753f617b4c72a15cd83d06ff629a69a",
     "grade": true,
     "grade_id": "cell-00dd74c3ff493d7d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4453c79fa588ec28dd223792b6ecc3ee",
     "grade": false,
     "grade_id": "cell-61f2183ac9d6e788",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex5: Setup Callback Functions and Train Model\n",
    "**<div style=\"text-align: right\"> [Score: 1]</div>**\n",
    "\n",
    "Train your model here\n",
    "-  Train your model with Model Checkpoint callback to save your model\n",
    "-  Comment out the training section before submitting. *Caution!!!*\n",
    "-  Submit by loading checkpoint weights of your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "19afce4d3eb1fdb86aec75737785be2c",
     "grade": false,
     "grade_id": "cell-e1a997a16af12799",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aab9b898754f1c45c4ada0a1b84091ca",
     "grade": true,
     "grade_id": "cell-8ba7321494f606d5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "83d673de075f5eff91e81011cb0139ae",
     "grade": false,
     "grade_id": "cell-62a8e84f3d93235c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 401s 8ms/step - loss: 0.2401 - acc: 0.9121 - val_loss: 0.2350 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91408, saving model to ./cp.ckpt\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 402s 8ms/step - loss: 0.2306 - acc: 0.9147 - val_loss: 0.2457 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91408\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 403s 8ms/step - loss: 0.2160 - acc: 0.9208 - val_loss: 0.2081 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91408 to 0.92900, saving model to ./cp.ckpt\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 396s 8ms/step - loss: 0.2075 - acc: 0.9237 - val_loss: 0.2239 - val_acc: 0.9195\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92900\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 402s 8ms/step - loss: 0.1980 - acc: 0.9269 - val_loss: 0.2135 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92900\n",
      "Epoch 6/10\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9318"
     ]
    }
   ],
   "source": [
    "NO_EPOCHS = None\n",
    "BATCH_SIZE = None\n",
    "train_model = None\n",
    "# YOUR CODE HERE\n",
    "NO_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "# train_model = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=BATCH_SIZE, epochs=NO_EPOCHS, callbacks=[cp_callback])\n",
    "# pred = model.predict(X_val)\n",
    "\n",
    "# print(classification_report(y_val.argmax(axis=1), pred.argmax(axis=1), target_names=list(labels.values())))\n",
    "\n",
    "# raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d576385c737de84257386fdce9f0f31",
     "grade": false,
     "grade_id": "cell-239e8bb9d1f02be4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex6: Load the Model\n",
    "**<div style=\"text-align: right\"> [Score: 9]</div>**\n",
    "Comment out the Previous Training section and load your model below before submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b5e5f9f968e89a0b19f49b8a82f31b5",
     "grade": false,
     "grade_id": "cell-6cfa1ba8b279a889",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### [Easy] You need to get at least 85% accuracy to pass this test\n",
    "### [Hard] To put your skills to the test try to get 95% or more. check the link on the top for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "239a2715d28fd81876c3fde37e6f7fe0",
     "grade": true,
     "grade_id": "cell-1b1fb5ffc528cd2f",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8714845f96f107f488957ac89be94d81",
     "grade": true,
     "grade_id": "cell-fff6ae52ef6fc75f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b81338bf2cd10c2f127c418f55877686",
     "grade": true,
     "grade_id": "cell-22c784fb551a3577",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1846bcf0274b947f40c492b14ca1033e",
     "grade": false,
     "grade_id": "cell-c9de459da25afe2c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##Congratulations, you have reached the end of the Assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
