{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c88e883a510a73441d81b3782d0fdae1",
     "grade": false,
     "grade_id": "cell-eeaf011f5870e5d5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Emotion Detection and Recognition\n",
    "**<div style=\"text-align: right\"> [Total score: 14]</div>**\n",
    "\n",
    "We detected emotions from the text using scikit-learn in module-2 project. Now, we will use keras with word embeddings and LSTM layers to make the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9abda80f7c9d44f4c1805d40ea6bfb4a",
     "grade": false,
     "grade_id": "cell-7bdb4f642629dd1d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex1: Import Keras and other libraries\n",
    "Don't forget to import embedding layer and LSTM from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "90d90727bac6bfe68ad2aa2c9b16f25c",
     "grade": false,
     "grade_id": "cell-276deba12a313fed",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras, string, nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41c810520342722619bf09437e3fcbf7",
     "grade": false,
     "grade_id": "cell-254f8531eaf6ca0b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex2: Load and Preprocess the Dataset\n",
    "**<div style=\"text-align: right\"> [Score: 1]</div>**\n",
    "1. Read the dataset ISEAR.csv which is in the current path.\n",
    "2. Set the column names to Emotions and Sentence.\n",
    "2. Visualize and clean the dataset.\n",
    "3. Perform any preprocessing that may be useful\n",
    "\n",
    "The data should possess only these emotions: 'joy', 'fear', 'anger', 'sadness', 'disgust', 'shame' and 'guilt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "42c1a08e1c66802fadd68bcb6d3f7387",
     "grade": false,
     "grade_id": "cell-358a4ddaeb3bb6d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                          Sentences\n",
       "0      joy  On days when I feel close to my partner and ot...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['Emotions', 'Sentence']\n",
    "df = pd.read_csv('ISEAR.csv', names = column_names)\n",
    "del df['Sentence']\n",
    "df = df.reset_index()\n",
    "df.rename(index = str, columns = {\"index\" :\"Emotions\", \"Emotions\" : \"Sentences\"}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7516</td>\n",
       "      <td>7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8</td>\n",
       "      <td>7449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>joy</td>\n",
       "      <td>When my grandfather died.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1092</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Emotions                  Sentences\n",
       "count      7516                       7516\n",
       "unique        8                       7449\n",
       "top         joy  When my grandfather died.\n",
       "freq       1092                          8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab6daed33c2fb2c8e8d8849b78ae8962",
     "grade": true,
     "grade_id": "cell-566d698aab697985",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "11bcb87ddddcf45be6d516d197c00c77",
     "grade": false,
     "grade_id": "cell-21b2150c1678d6a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex3: Clean the dataset\n",
    "**<div style=\"text-align: right\"> [Score: 1]</div>**\n",
    "1. Check if any values in the dataset contains null.\n",
    "2. Drop all the null values if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c70c74d1a008efd0365b5836de73a616",
     "grade": false,
     "grade_id": "cell-2da381c203e3fcca",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "109009f56d96fde817e123063bfcd2f1",
     "grade": true,
     "grade_id": "cell-a4ba5f94e7040619",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The emotions to be classified are: ['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt', 'guit']\n"
     ]
    }
   ],
   "source": [
    "print(\"The emotions to be classified are: \"+ str(list(df.Emotions.unique().tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b7c9e6b91118efd5eae88a49874d1dbf",
     "grade": false,
     "grade_id": "cell-9140e9b8574ca531",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Are you sure your data is clean ? <br>\n",
    "See if the spelling of guilt is incorrectly written as guit in some sentences.<br>\n",
    "**<div style=\"text-align: right\"> [Score: 1]</div>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f2cc16d754dddaac9ccce35e0dfebf43",
     "grade": false,
     "grade_id": "cell-ccd54ca3f6c8e4bb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to classify 7 emotions now.\n",
      "The emotions to be classified are: ['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df[\"Emotions\"].replace(\"guit\", \"guilt\", inplace = True)\n",
    "print(\"We need to classify \"+ str(df.Emotions.nunique()) +\" emotions now.\")\n",
    "print(\"The emotions to be classified are: \"+ str(list(df.Emotions.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'anger': 1079,\n",
       "         'disgust': 1066,\n",
       "         'fear': 1076,\n",
       "         'guilt': 1050,\n",
       "         'joy': 1092,\n",
       "         'sadness': 1082,\n",
       "         'shame': 1071})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df[\"Emotions\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ac7c9f0ad2084079070fcb607843b93",
     "grade": true,
     "grade_id": "cell-e4f79db38b3fdb6a",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4275a96932592380f10cceb570e84d0b",
     "grade": false,
     "grade_id": "cell-0851ddd00abab8fb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex4: Further NLP based text Cleaning (Not Necessary to Implement all)\n",
    "You can try \n",
    "- removing punctuations,\n",
    "- converting words to lower case \n",
    "- using the stem of each word\n",
    "- other preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fusemachines/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f3311d183a10d15075135b06cb6a6b3f",
     "grade": false,
     "grade_id": "cell-338f3d531c3e76fe",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.translate(string.punctuation)\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "   \n",
    "df['Sentences'] = df['Sentences'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['Sentences'], df['Emotions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "229e9517d8469d1f031a0a237418929c",
     "grade": false,
     "grade_id": "cell-a695521761295afe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex5: Transform y to one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "84a1d2d14dbaa22ce18c5bdee50c7609",
     "grade": false,
     "grade_id": "cell-f7f232a9a6f87ca7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "onehot_y = None\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoded_y = encoder.fit_transform(y)\n",
    "onehot_y = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "862d633aedbe0c2f4760779ce47f7707",
     "grade": false,
     "grade_id": "cell-d3313a24c90cc1e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex  6: Tokenize the sentences\n",
    "Tokenization of sentences is one of the essential parts in natural language processing. Tokenization simply divides a sentence into a list of words. \n",
    "<br>We will use Keras tokenizer function to tokenize the strings and ‘texts_to_sequences’ to make sequences of words. You might also want to pad the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words :  80896\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "a = [vocab.add(el) for s in X.values for el in s.split(' ')]\n",
    "print(\"Total unique words : \", len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min :  4\n",
      "Median :  63.0\n",
      "Max :  528\n"
     ]
    }
   ],
   "source": [
    "l = [len(s) for s in X.values]\n",
    "counts = Counter(l)\n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.show()\n",
    "print(\"Min : \", min(l))\n",
    "print(\"Median : \", np.median(l))\n",
    "print(\"Max : \", max(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "336ced219c4c1e3f32ec300a47fb84ee",
     "grade": false,
     "grade_id": "cell-c829adb8ca47ac6d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "vocabulary_size = None  # Select an Appropriate Vobabulary Size\n",
    "padded_length = None  # Select an Appropriate padded Length for text\n",
    "tokenizer = None \n",
    "# YOUR CODE HERE\n",
    "vocabulary_size = 80896\n",
    "padded_length = 155\n",
    "tokenizer = Tokenizer(num_words = vocabulary_size)\n",
    "tokenizer.fit_on_texts(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d56fb2452a0868d6297b0b4a285d8dac",
     "grade": false,
     "grade_id": "cell-bf49f90cc5cd38ee",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(X):\n",
    "    sequences = tokenizer.texts_to_sequences(X)\n",
    "    data = pad_sequences(sequences, maxlen = padded_length)\n",
    "    return data\n",
    "data = preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e323c013495d69d10eab2752383a1282",
     "grade": false,
     "grade_id": "cell-6a1789906e3f50a4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex7: Split the data into Train and Test\n",
    "Split the data into train and test with padded sequences as input and the encoded categorical y as the output; test size of 0.1 and random state of 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3ab91334e974c9f1f5b569cfcabda43e",
     "grade": false,
     "grade_id": "cell-1c4b0fed651b6a89",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, onehot_y, test_size = 0.1, random_state = 101, stratify = onehot_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2fcb841bb2fa9befb6e3731a32ca989a",
     "grade": false,
     "grade_id": "cell-7e856c842981ed86",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex8: Model and Compile your Neural Network Architecture\n",
    "**<div style=\"text-align: right\"> [Score: 2]</div>**\n",
    "Try to Include \n",
    "1. Embedding layer\n",
    "2. LSTM with dropout\n",
    "3. Dense Output layere\n",
    "4. Use any other layers as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cb9620bd6366225ea01222c99e22457e",
     "grade": false,
     "grade_id": "cell-fd5782425382cc4c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 155, 200)          16179200  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                67840     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 16,249,351\n",
      "Trainable params: 16,249,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "learning_rate = 1e-2\n",
    "numEpoch = 50\n",
    "embedding_size = 200\n",
    "lstm_size = 64\n",
    "seed = 2019\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers, regularizers\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "def create_model(embedding_size = 100, lstm_size = 32, layer1_size = 32, dropoutrate = 0.3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Embedding(vocabulary_size, embedding_size, input_length = padded_length, embeddings_regularizer = regularizers.l1(0.001)))\n",
    "    model.add(LSTM(lstm_size, dropout = dropoutrate, recurrent_dropout = dropoutrate))\n",
    "    model.add(Dense(layer1_size, activation = 'relu'))\n",
    "    model.add(Dropout(dropoutrate, seed = seed))\n",
    "    model.add(Dense(7, activation = \"softmax\"))\n",
    "    \n",
    "    optim = optimizers.Adam(lr = learning_rate, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = learning_rate/numEpoch)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optim, metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "model = create_model(embedding_size = embedding_size, lstm_size = lstm_size, layer1_size = 32, dropoutrate = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5688ff0650a9037ebd302b68ea3e576e",
     "grade": true,
     "grade_id": "cell-6000a781a6d4e033",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54715de4ea2b48e8ca07935f03148eeb",
     "grade": false,
     "grade_id": "cell-121e6c86aeb486c4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Ex9: Set Callback functions and Train your Model\n",
    "Must include ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e38104e1f94aecb6204d73a4398fac8e",
     "grade": false,
     "grade_id": "cell-2b038cd9acff27e1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'best_model.h5'\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 3),\n",
    "            ModelCheckpoint(checkpoint_path, save_weights_only = True, save_best_only = True, verbose = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54d13471999efb497adcaa0ee2b391ad",
     "grade": false,
     "grade_id": "cell-9a4744e34f749142",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Caution** Comment out the training section before submitting. Submit the code by loading Checkpoint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9a80745fca13031e6a75172f350e6a46",
     "grade": false,
     "grade_id": "cell-046882fee429c7b3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6178697f32ea28437c4c8737623e21e7",
     "grade": false,
     "grade_id": "cell-da3734217f0808b0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5411 samples, validate on 1353 samples\n",
      "Epoch 1/50\n",
      "5411/5411 [==============================] - 217s 40ms/step - loss: 34.9185 - acc: 0.1613 - val_loss: 23.2635 - val_acc: 0.2114\n",
      "Epoch 2/50\n",
      "5411/5411 [==============================] - 195s 36ms/step - loss: 22.6991 - acc: 0.2382 - val_loss: 23.7615 - val_acc: 0.2676\n",
      "Epoch 3/50\n",
      "3296/5411 [=================>............] - ETA: 1:20 - loss: 22.1308 - acc: 0.2633"
     ]
    }
   ],
   "source": [
    "# Train your model\n",
    "# history = model.fit(X_train, y_train, batch_size = 32, validation_split = 0.2, epochs = numEpoch, callbacks= callbacks)\n",
    "# plot(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "be94367e3458bf5d4e756255f55ff6b7",
     "grade": false,
     "grade_id": "cell-2bcd14f184337c18",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Final Task\n",
    "**<div style=\"text-align: right\"> [Score: 9]</div>**\n",
    "Comment out the previous training section and submit by loading your checkpoint below\n",
    "As the Dataset is small your test score and accuracy may be less but will probably perform better in hidden test set.\n",
    "Aim to achieve a score higher than 50 % or higher than your scikit learn project on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model = model.load_weights(checkpoint_path)\n",
    "score = model.evaluate(X_test, y_test) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "test_y = encoder.inverse_transform(np.argmax(y_test, axis=1, out=None))\n",
    "pred_y = encoder.inverse_transform(np.argmax(prediction, axis=1, out=None))\n",
    "print(metrics.classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(test_y, pred_y)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ticks =encoder.inverse_transform(range(7)).astype(str)\n",
    "plt.xticks(range(7), ticks)\n",
    "plt.yticks(range(7), ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2157de83f411b03704c10b44d3cc052b",
     "grade": true,
     "grade_id": "cell-d7df9047789247be",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a3250bf36970894b0e2388c96a79f1c6",
     "grade": true,
     "grade_id": "cell-ff0b6cf7648e7f8f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3765b5a7bc541980262219837e1e5764",
     "grade": true,
     "grade_id": "cell-8993d5890bfc91ed",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#### INTENTIONALLY LEFT BLANK####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "302a15e370ee01a8540e9def5ff35326",
     "grade": false,
     "grade_id": "cell-debd21510fba02c5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Congratulations, you have reached the end of the Assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
